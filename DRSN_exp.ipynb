{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "from openpyxl import Workbook\n",
    "from datetime import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "# Class Defined by the Project\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_file():\n",
    "    data_filename = 'ES1.csv'\n",
    "    if not os.path.exists(data_filename):\n",
    "        print(\"Error: Missing file \\'%s\\'\" % data_filename)\n",
    "        return\n",
    "    #pandas 读取csv文件：向量维度：1*1*8 ,列表用法\n",
    "    test_data = pandas.read_csv(data_filename, names=[\"Flag\", \"L1\", \"L2\", \"L3\", \"L4\", \"R1\", \"R2\", \"R3\", \"R4\"])\n",
    "    return test_data\n",
    "\n",
    "\n",
    "def data_prepare():\n",
    "    value_data = read_data_file()\n",
    "    value_data = value_data.values\n",
    "    print(value_data.shape)\n",
    "\n",
    "    label = value_data[:, 0] #取第一列元素\n",
    "    datav = value_data[:, 1:] #取第一列剩余的元素\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(datav)\n",
    "    datas = scaler.transform(datav) #为什么要用transform\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(datas, label, test_size=0.2, random_state=2021, stratify=label)\n",
    "    x_verify = x_test.copy()\n",
    "    y_verify = y_test.copy()\n",
    "\n",
    "    print(\"Train dim =\")\n",
    "    print(x_train.shape)\n",
    "    print(\"Train Label dim =\")\n",
    "    print(y_train.shape)\n",
    "    print(\"Verify dim =\")\n",
    "    print(x_verify.shape)\n",
    "    print(\"Verify Label dim =\")\n",
    "    print(y_verify.shape)\n",
    "    print(\"Test dim =\")\n",
    "    print(x_test.shape)\n",
    "    print(\"Test Label dim =\")\n",
    "    print(y_test.shape)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test, x_verify, y_verify\n",
    "\n",
    "\n",
    "class OneDimData(Dataset):  # 继承Dataset\n",
    "    def __init__(self, datav, label, transform=None):  # __init__是初始化该类的一些基础参数\n",
    "\n",
    "        self.data = datav\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):  # 返回整个数据集的大小\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):  # 根据索引index返回dataset[index]\n",
    "        sample = self.data[index, :]  # 根据索引index获取\n",
    "        sampleflag = self.label[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)  # 对样本进行变换\n",
    "\n",
    "        return sample.astype(np.float32), sampleflag.astype(np.int64)  # 返回该样本\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实现的是C*W*1的从池化到软阈值的实现过程，并不是整个模块。\n",
    "#but the question is : I just have 1_D vector,if I need to rectify the net and do other things? \n",
    "#I think I should just try this method first,then consider other things.\n",
    "#输入参数只是x,需要的gap_size=1 和channel=1 已经设定好\n",
    "class Shrinkage(nn.Module):\n",
    "    def __init__(self, gap_size=1,channel=1):\n",
    "        super(Shrinkage, self).__init__()\n",
    "        self.gap = nn.AdaptiveAvgPool2d(gap_size) #output size=gap_size*gap_size\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel),\n",
    "            nn.BatchNorm1d(channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel, 1),# 可能应该是nn.Linear(channel, channel)\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x_raw = x #x_raw=1*w*1\n",
    "        x = torch.abs(x) #取绝对值\n",
    "        x_abs = x #x_abs 副本=1*w*1\n",
    "        x = self.gap(x) #池化 output_size=1*1*1\n",
    "        x = torch.flatten(x, 1) # \n",
    "        average = x\n",
    "        x = self.fc(x)\n",
    "        x = torch.mul(average, x) #逐元素相乘\n",
    "        x = x.unsqueeze(2).unsqueeze(2)\n",
    "        # 软阈值化\n",
    "        sub = x_abs - x #x就是keras代码中的阈值thres\n",
    "        zeros = sub - sub\n",
    "        n_sub = torch.max(sub, zeros)\n",
    "        x = torch.mul(torch.sign(x_raw), n_sub) \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net=DRSN()\n",
    "# img = torch.randn(32,1, 1, 8)\n",
    "# preds = net(img) \n",
    "# print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要的参数 cin=1,cout=1，已经设定好，不再需要其他参数\n",
    "class DRSNBlock(nn.Module):\n",
    "    def __init__(self,cin=1,cout=1):\n",
    "        super(DRSNBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(cin, cout, 1), # in_channels, out_channels, kernel_size\n",
    "            nn.BatchNorm2d(cout,eps=1e-5, momentum=0.01, affine=True),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(cin, cout, 1), # in_channels, out_channels, kernel_size\n",
    "            nn.BatchNorm2d(cout,eps=1e-5, momentum=0.01, affine=True),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.shrink=Shrinkage()\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.shrink(x)\n",
    "        x = identity + x\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net=DRSNBlock()\n",
    "# img = torch.randn(32,1, 1, 8)\n",
    "# preds = net(img) \n",
    "# print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要的参数 cin=1,cout=1，已经设定好，不再需要其他参数\n",
    "class DRSN(nn.Module):\n",
    "    def __init__(self,cin=1,cout=1):\n",
    "        super(DRSN, self).__init__()\n",
    "        self.block=DRSNBlock()\n",
    "        self.dropout=nn.Dropout(0.5)\n",
    "        #数字由计算得出\n",
    "        self.linear1=nn.Linear(8, 16)\n",
    "        self.linear2=nn.Linear(16,2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if not torch.is_tensor(x):\n",
    "            x=torch.from_numpy(x)\n",
    "        batch = x.shape[0]\n",
    "        x=torch.reshape(x,(batch,1,1,-1))        \n",
    "        x=self.block(x)\n",
    "        x=self.block(x)\n",
    "        x=self.block(x)\n",
    "        x=self.linear1(x)\n",
    "        x=self.linear2(x)\n",
    "        x=torch.reshape(x,(batch,-1))\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.xavier_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                torch.nn.init.normal_(m.weight.data, 0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net=DRSN()\n",
    "# img = torch.randn(32,1, 1, 8)\n",
    "# preds = net(img) \n",
    "# print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203, 9)\n",
      "Train dim =\n",
      "(162, 8)\n",
      "Train Label dim =\n",
      "(162,)\n",
      "Verify dim =\n",
      "(41, 8)\n",
      "Verify Label dim =\n",
      "(41,)\n",
      "Test dim =\n",
      "(41, 8)\n",
      "Test Label dim =\n",
      "(41,)\n",
      "Training: Epoch[001/100] Iteration[006/006] Loss: 0.4308 Acc:48.7654%\n",
      "Epoch=0 -  Test set Accuracy:46.3415%\n",
      "Training: Epoch[002/100] Iteration[006/006] Loss: 0.4227 Acc:49.3827%\n",
      "Epoch=1 -  Test set Accuracy:48.7805%\n",
      "Training: Epoch[003/100] Iteration[006/006] Loss: 0.4142 Acc:52.4691%\n",
      "Epoch=2 -  Test set Accuracy:53.6585%\n",
      "Training: Epoch[004/100] Iteration[006/006] Loss: 0.4124 Acc:55.5556%\n",
      "Epoch=3 -  Test set Accuracy:63.4146%\n",
      "Training: Epoch[005/100] Iteration[006/006] Loss: 0.4018 Acc:53.0864%\n",
      "Epoch=4 -  Test set Accuracy:65.8537%\n",
      "Training: Epoch[006/100] Iteration[006/006] Loss: 0.4058 Acc:58.6420%\n",
      "Epoch=5 -  Test set Accuracy:70.7317%\n",
      "Training: Epoch[007/100] Iteration[006/006] Loss: 0.4031 Acc:58.6420%\n",
      "Epoch=6 -  Test set Accuracy:56.0976%\n",
      "Training: Epoch[008/100] Iteration[006/006] Loss: 0.4080 Acc:54.9383%\n",
      "Epoch=7 -  Test set Accuracy:56.0976%\n",
      "Training: Epoch[009/100] Iteration[006/006] Loss: 0.3874 Acc:54.3210%\n",
      "Epoch=8 -  Test set Accuracy:53.6585%\n",
      "Training: Epoch[010/100] Iteration[006/006] Loss: 0.3846 Acc:54.3210%\n",
      "Epoch=9 -  Test set Accuracy:51.2195%\n",
      "Training: Epoch[011/100] Iteration[006/006] Loss: 0.3853 Acc:53.7037%\n",
      "Epoch=10 -  Test set Accuracy:53.6585%\n",
      "Training: Epoch[012/100] Iteration[006/006] Loss: 0.4240 Acc:53.7037%\n",
      "Epoch=11 -  Test set Accuracy:53.6585%\n",
      "Training: Epoch[013/100] Iteration[006/006] Loss: 0.4043 Acc:53.7037%\n",
      "Epoch=12 -  Test set Accuracy:53.6585%\n",
      "Training: Epoch[014/100] Iteration[006/006] Loss: 0.4054 Acc:53.7037%\n",
      "Epoch=13 -  Test set Accuracy:51.2195%\n",
      "Training: Epoch[015/100] Iteration[006/006] Loss: 0.4142 Acc:54.3210%\n",
      "Epoch=14 -  Test set Accuracy:53.6585%\n",
      "Training: Epoch[016/100] Iteration[006/006] Loss: 0.3749 Acc:54.3210%\n",
      "Epoch=15 -  Test set Accuracy:56.0976%\n",
      "Training: Epoch[017/100] Iteration[006/006] Loss: 0.3996 Acc:54.9383%\n",
      "Epoch=16 -  Test set Accuracy:56.0976%\n",
      "Training: Epoch[018/100] Iteration[006/006] Loss: 0.3985 Acc:57.4074%\n",
      "Epoch=17 -  Test set Accuracy:56.0976%\n",
      "Training: Epoch[019/100] Iteration[006/006] Loss: 0.4001 Acc:61.1111%\n",
      "Epoch=18 -  Test set Accuracy:60.9756%\n",
      "Training: Epoch[020/100] Iteration[006/006] Loss: 0.3916 Acc:66.6667%\n",
      "Epoch=19 -  Test set Accuracy:68.2927%\n",
      "Training: Epoch[021/100] Iteration[006/006] Loss: 0.4035 Acc:67.2840%\n",
      "Epoch=20 -  Test set Accuracy:63.4146%\n",
      "Training: Epoch[022/100] Iteration[006/006] Loss: 0.3961 Acc:68.5185%\n",
      "Epoch=21 -  Test set Accuracy:68.2927%\n",
      "Training: Epoch[023/100] Iteration[006/006] Loss: 0.3788 Acc:70.9877%\n",
      "Epoch=22 -  Test set Accuracy:68.2927%\n",
      "Training: Epoch[024/100] Iteration[006/006] Loss: 0.3773 Acc:69.7531%\n",
      "Epoch=23 -  Test set Accuracy:58.5366%\n",
      "Training: Epoch[025/100] Iteration[006/006] Loss: 0.3841 Acc:67.2840%\n",
      "Epoch=24 -  Test set Accuracy:56.0976%\n",
      "Training: Epoch[026/100] Iteration[006/006] Loss: 0.3847 Acc:63.5802%\n",
      "Epoch=25 -  Test set Accuracy:56.0976%\n",
      "Training: Epoch[027/100] Iteration[006/006] Loss: 0.3803 Acc:56.7901%\n",
      "Epoch=26 -  Test set Accuracy:53.6585%\n",
      "Training: Epoch[028/100] Iteration[006/006] Loss: 0.3649 Acc:54.9383%\n",
      "Epoch=27 -  Test set Accuracy:51.2195%\n",
      "Training: Epoch[029/100] Iteration[006/006] Loss: 0.3830 Acc:55.5556%\n",
      "Epoch=28 -  Test set Accuracy:51.2195%\n",
      "Training: Epoch[030/100] Iteration[006/006] Loss: 0.3627 Acc:54.3210%\n",
      "Epoch=29 -  Test set Accuracy:51.2195%\n",
      "Training: Epoch[031/100] Iteration[006/006] Loss: 0.3912 Acc:54.3210%\n",
      "Epoch=30 -  Test set Accuracy:51.2195%\n",
      "Training: Epoch[032/100] Iteration[006/006] Loss: 0.3953 Acc:54.3210%\n",
      "Epoch=31 -  Test set Accuracy:51.2195%\n",
      "Training: Epoch[033/100] Iteration[006/006] Loss: 0.4116 Acc:58.0247%\n",
      "Epoch=32 -  Test set Accuracy:56.0976%\n",
      "Training: Epoch[034/100] Iteration[006/006] Loss: 0.3828 Acc:61.7284%\n",
      "Epoch=33 -  Test set Accuracy:58.5366%\n",
      "Training: Epoch[035/100] Iteration[006/006] Loss: 0.3985 Acc:69.1358%\n",
      "Epoch=34 -  Test set Accuracy:65.8537%\n",
      "Training: Epoch[036/100] Iteration[006/006] Loss: 0.3510 Acc:74.0741%\n",
      "Epoch=35 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[037/100] Iteration[006/006] Loss: 0.3843 Acc:69.7531%\n",
      "Epoch=36 -  Test set Accuracy:65.8537%\n",
      "Training: Epoch[038/100] Iteration[006/006] Loss: 0.3759 Acc:69.1358%\n",
      "Epoch=37 -  Test set Accuracy:65.8537%\n",
      "Training: Epoch[039/100] Iteration[006/006] Loss: 0.3729 Acc:71.6049%\n",
      "Epoch=38 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[040/100] Iteration[006/006] Loss: 0.3756 Acc:72.8395%\n",
      "Epoch=39 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[041/100] Iteration[006/006] Loss: 0.3657 Acc:75.9259%\n",
      "Epoch=40 -  Test set Accuracy:73.1707%\n",
      "Training: Epoch[042/100] Iteration[006/006] Loss: 0.3571 Acc:74.6914%\n",
      "Epoch=41 -  Test set Accuracy:78.0488%\n",
      "Training: Epoch[043/100] Iteration[006/006] Loss: 0.3396 Acc:74.0741%\n",
      "Epoch=42 -  Test set Accuracy:80.4878%\n",
      "Training: Epoch[044/100] Iteration[006/006] Loss: 0.3485 Acc:70.9877%\n",
      "Epoch=43 -  Test set Accuracy:65.8537%\n",
      "Training: Epoch[045/100] Iteration[006/006] Loss: 0.3653 Acc:68.5185%\n",
      "Epoch=44 -  Test set Accuracy:68.2927%\n",
      "Training: Epoch[046/100] Iteration[006/006] Loss: 0.3479 Acc:70.9877%\n",
      "Epoch=45 -  Test set Accuracy:68.2927%\n",
      "Training: Epoch[047/100] Iteration[006/006] Loss: 0.3605 Acc:70.9877%\n",
      "Epoch=46 -  Test set Accuracy:63.4146%\n",
      "Training: Epoch[048/100] Iteration[006/006] Loss: 0.3578 Acc:71.6049%\n",
      "Epoch=47 -  Test set Accuracy:63.4146%\n",
      "Training: Epoch[049/100] Iteration[006/006] Loss: 0.3650 Acc:70.9877%\n",
      "Epoch=48 -  Test set Accuracy:68.2927%\n",
      "Training: Epoch[050/100] Iteration[006/006] Loss: 0.3806 Acc:72.2222%\n",
      "Epoch=49 -  Test set Accuracy:70.7317%\n",
      "Training: Epoch[051/100] Iteration[006/006] Loss: 0.3496 Acc:72.8395%\n",
      "Epoch=50 -  Test set Accuracy:73.1707%\n",
      "Training: Epoch[052/100] Iteration[006/006] Loss: 0.3450 Acc:71.6049%\n",
      "Epoch=51 -  Test set Accuracy:73.1707%\n",
      "Training: Epoch[053/100] Iteration[006/006] Loss: 0.3539 Acc:72.2222%\n",
      "Epoch=52 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[054/100] Iteration[006/006] Loss: 0.3347 Acc:73.4568%\n",
      "Epoch=53 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[055/100] Iteration[006/006] Loss: 0.3615 Acc:73.4568%\n",
      "Epoch=54 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[056/100] Iteration[006/006] Loss: 0.3474 Acc:72.8395%\n",
      "Epoch=55 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[057/100] Iteration[006/006] Loss: 0.3269 Acc:72.2222%\n",
      "Epoch=56 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[058/100] Iteration[006/006] Loss: 0.3438 Acc:74.6914%\n",
      "Epoch=57 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[059/100] Iteration[006/006] Loss: 0.3575 Acc:72.2222%\n",
      "Epoch=58 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[060/100] Iteration[006/006] Loss: 0.3651 Acc:72.8395%\n",
      "Epoch=59 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[061/100] Iteration[006/006] Loss: 0.3404 Acc:74.0741%\n",
      "Epoch=60 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[062/100] Iteration[006/006] Loss: 0.3535 Acc:72.8395%\n",
      "Epoch=61 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[063/100] Iteration[006/006] Loss: 0.3743 Acc:73.4568%\n",
      "Epoch=62 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[064/100] Iteration[006/006] Loss: 0.3390 Acc:72.2222%\n",
      "Epoch=63 -  Test set Accuracy:73.1707%\n",
      "Training: Epoch[065/100] Iteration[006/006] Loss: 0.3590 Acc:74.6914%\n",
      "Epoch=64 -  Test set Accuracy:73.1707%\n",
      "Training: Epoch[066/100] Iteration[006/006] Loss: 0.3252 Acc:72.8395%\n",
      "Epoch=65 -  Test set Accuracy:80.4878%\n",
      "Training: Epoch[067/100] Iteration[006/006] Loss: 0.3549 Acc:72.2222%\n",
      "Epoch=66 -  Test set Accuracy:80.4878%\n",
      "Training: Epoch[068/100] Iteration[006/006] Loss: 0.3528 Acc:74.0741%\n",
      "Epoch=67 -  Test set Accuracy:80.4878%\n",
      "Training: Epoch[069/100] Iteration[006/006] Loss: 0.3274 Acc:74.6914%\n",
      "Epoch=68 -  Test set Accuracy:80.4878%\n",
      "Training: Epoch[070/100] Iteration[006/006] Loss: 0.3502 Acc:75.3086%\n",
      "Epoch=69 -  Test set Accuracy:80.4878%\n",
      "Training: Epoch[071/100] Iteration[006/006] Loss: 0.3712 Acc:74.6914%\n",
      "Epoch=70 -  Test set Accuracy:80.4878%\n",
      "Training: Epoch[072/100] Iteration[006/006] Loss: 0.3554 Acc:73.4568%\n",
      "Epoch=71 -  Test set Accuracy:80.4878%\n",
      "Training: Epoch[073/100] Iteration[006/006] Loss: 0.3445 Acc:74.0741%\n",
      "Epoch=72 -  Test set Accuracy:80.4878%\n",
      "Training: Epoch[074/100] Iteration[006/006] Loss: 0.3511 Acc:73.4568%\n",
      "Epoch=73 -  Test set Accuracy:80.4878%\n",
      "Training: Epoch[075/100] Iteration[006/006] Loss: 0.3450 Acc:73.4568%\n",
      "Epoch=74 -  Test set Accuracy:82.9268%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch[076/100] Iteration[006/006] Loss: 0.3335 Acc:75.3086%\n",
      "Epoch=75 -  Test set Accuracy:82.9268%\n",
      "Training: Epoch[077/100] Iteration[006/006] Loss: 0.3548 Acc:72.8395%\n",
      "Epoch=76 -  Test set Accuracy:82.9268%\n",
      "Training: Epoch[078/100] Iteration[006/006] Loss: 0.3674 Acc:72.2222%\n",
      "Epoch=77 -  Test set Accuracy:80.4878%\n",
      "Training: Epoch[079/100] Iteration[006/006] Loss: 0.3331 Acc:74.0741%\n",
      "Epoch=78 -  Test set Accuracy:82.9268%\n",
      "Training: Epoch[080/100] Iteration[006/006] Loss: 0.3552 Acc:73.4568%\n",
      "Epoch=79 -  Test set Accuracy:82.9268%\n",
      "Training: Epoch[081/100] Iteration[006/006] Loss: 0.3645 Acc:73.4568%\n",
      "Epoch=80 -  Test set Accuracy:82.9268%\n",
      "Training: Epoch[082/100] Iteration[006/006] Loss: 0.3545 Acc:73.4568%\n",
      "Epoch=81 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[083/100] Iteration[006/006] Loss: 0.3572 Acc:76.5432%\n",
      "Epoch=82 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[084/100] Iteration[006/006] Loss: 0.3444 Acc:71.6049%\n",
      "Epoch=83 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[085/100] Iteration[006/006] Loss: 0.3542 Acc:77.1605%\n",
      "Epoch=84 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[086/100] Iteration[006/006] Loss: 0.3626 Acc:72.8395%\n",
      "Epoch=85 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[087/100] Iteration[006/006] Loss: 0.3654 Acc:75.9259%\n",
      "Epoch=86 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[088/100] Iteration[006/006] Loss: 0.3593 Acc:75.3086%\n",
      "Epoch=87 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[089/100] Iteration[006/006] Loss: 0.3540 Acc:76.5432%\n",
      "Epoch=88 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[090/100] Iteration[006/006] Loss: 0.3359 Acc:74.0741%\n",
      "Epoch=89 -  Test set Accuracy:75.6098%\n",
      "Training: Epoch[091/100] Iteration[006/006] Loss: 0.3239 Acc:72.8395%\n",
      "Epoch=90 -  Test set Accuracy:82.9268%\n",
      "Training: Epoch[092/100] Iteration[006/006] Loss: 0.3531 Acc:76.5432%\n",
      "Epoch=91 -  Test set Accuracy:82.9268%\n",
      "Training: Epoch[093/100] Iteration[006/006] Loss: 0.3510 Acc:76.5432%\n",
      "Epoch=92 -  Test set Accuracy:80.4878%\n",
      "Training: Epoch[094/100] Iteration[006/006] Loss: 0.3468 Acc:77.7778%\n",
      "Epoch=93 -  Test set Accuracy:78.0488%\n",
      "Training: Epoch[095/100] Iteration[006/006] Loss: 0.3623 Acc:74.6914%\n",
      "Epoch=94 -  Test set Accuracy:80.4878%\n",
      "Training: Epoch[096/100] Iteration[006/006] Loss: 0.3563 Acc:77.1605%\n",
      "Epoch=95 -  Test set Accuracy:80.4878%\n",
      "Training: Epoch[097/100] Iteration[006/006] Loss: 0.3304 Acc:78.3951%\n",
      "Epoch=96 -  Test set Accuracy:80.4878%\n",
      "Training: Epoch[098/100] Iteration[006/006] Loss: 0.3482 Acc:75.3086%\n",
      "Epoch=97 -  Test set Accuracy:80.4878%\n",
      "Training: Epoch[099/100] Iteration[006/006] Loss: 0.3440 Acc:77.7778%\n",
      "Epoch=98 -  Test set Accuracy:80.4878%\n",
      "Training: Epoch[100/100] Iteration[006/006] Loss: 0.3439 Acc:74.6914%\n",
      "Epoch=99 -  Test set Accuracy:80.4878%\n",
      "finished training\n",
      "ACC= 82.9268%\n",
      "<class 'numpy.ndarray'>\n",
      "TP=  18\n",
      "FN=  4\n",
      "FP=  3\n",
      "TN=  16\n"
     ]
    }
   ],
   "source": [
    "def es_pred_disease():\n",
    "    x_train, x_test, y_train, y_test, x_verify, y_verify = data_prepare()\n",
    "\n",
    "    # Hyper Parameters\n",
    "    max_epoch = 100  # 训练整批数据多少次\n",
    "    batch_size = 32\n",
    "    lr_init = 0.001  # 学习率\n",
    "\n",
    "    xtrain = OneDimData(x_train, y_train)\n",
    "    xverify = OneDimData(x_verify, y_verify)\n",
    "    xtest = OneDimData(x_test, y_test)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=xtrain, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=xtest, batch_size=batch_size, shuffle=True)\n",
    "    cnn = DRSN()\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()  # 选择损失函数\n",
    "    optimizer = optim.SGD(cnn.parameters(), lr=lr_init, momentum=0.9, dampening=0.1)  # 选择优化器\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)  # 设置学习率下降策略\n",
    "\n",
    "    now_time = datetime.now()\n",
    "    time_str = datetime.strftime(now_time, '%m-%d_%H-%M-%S')\n",
    "    writer = SummaryWriter(log_dir=\"./\")\n",
    "\n",
    "    max_acc=0\n",
    "    \n",
    "    for epoch in range(max_epoch):\n",
    "\n",
    "        loss_sigma = 0.0  # 记录一个epoch的loss之和\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        \n",
    "        #训练模式\n",
    "        for step, (b_x, b_y) in enumerate(train_loader):  #for j ,(in,label)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = cnn(b_x)\n",
    "            loss = loss_function(outputs, b_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += b_y.size(0)\n",
    "            correct += (predicted == b_y).squeeze().sum().numpy()\n",
    "            loss_sigma += loss.item()\n",
    "\n",
    "            if step % 10 == 5:\n",
    "                loss_avg = loss_sigma / 10\n",
    "                loss_sigma = 0.0\n",
    "                print(\"Training: Epoch[{:0>3}/{:0>3}] Iteration[{:0>3}/{:0>3}] Loss: {:.4f} Acc:{:.4%}\".format(\n",
    "                    epoch + 1, max_epoch, step + 1, len(train_loader), loss_avg, correct / total))\n",
    "\n",
    "        scheduler.step()  # 更新学习率\n",
    "        loss_sigma = 0.0\n",
    "        cls_num = 2\n",
    "        conf_mat = np.zeros([cls_num, cls_num])  # 混淆矩阵\n",
    "        \n",
    "        #评估模式\n",
    "        cnn.eval()\n",
    "        outputs = cnn(x_verify.astype(np.float32))\n",
    "        outputs.detach()\n",
    "\n",
    "        y2 = torch.from_numpy(y_verify.astype(np.int64))\n",
    "        y2 = torch.reshape(y2,(-1,1))\n",
    "        y2 = y2.squeeze_()\n",
    "        loss = loss_function(outputs,y2)\n",
    "        loss_sigma += loss.item()\n",
    "\n",
    "        cnn.train()\n",
    "        \n",
    "        test_out = outputs\n",
    "        predict_y = torch.argmax(test_out, 1).data.numpy()\n",
    "        current_acc = sum(predict_y == y_test) * 100 / len(predict_y)\n",
    "        if current_acc > max_acc:\n",
    "            max_acc = current_acc\n",
    "            max_test = predict_y\n",
    "            net_save_path = os.path.join(r'E:\\Data\\code\\Mr.ma\\model_save', 'model_best.pt')\n",
    "            torch.save(cnn, net_save_path)\n",
    "\n",
    "        print('Epoch={} -  Test set Accuracy:{:.4%}'.format( epoch,  current_acc/100.0 ))\n",
    "\n",
    "    print('finished training')\n",
    "    print('ACC= %.4f%%' % max_acc)\n",
    "    print(type(max_test))\n",
    "#     print(max_test)\n",
    "#     print(y_test)\n",
    "\n",
    "    a=max_test-y_test\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    for i in range (41):\n",
    "        if a[i]==1:\n",
    "            FN+=1\n",
    "        if a[i]==-1:\n",
    "            FP+=1\n",
    "        TP=22-FN\n",
    "        TN=19-FP\n",
    "    print(\"TP= \",TP)\n",
    "    print(\"FN= \",FN)\n",
    "    print(\"FP= \",FP)\n",
    "    print(\"TN= \",TN)\n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "es_pred_disease()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-230270f8912e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'max_test' is not defined"
     ]
    }
   ],
   "source": [
    "print(type(max_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(nn.AdaptiveAvgPool2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a15c5c827a1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mloss_sigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m  \u001b[1;31m# 记录一个epoch的loss之和\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'max_epoch' is not defined"
     ]
    }
   ],
   "source": [
    "    for epoch in range(max_epoch):\n",
    "\n",
    "        loss_sigma = 0.0  # 记录一个epoch的loss之和\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "        for step, (b_x, b_y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = cnn(b_x)\n",
    "            loss = loss_function(outputs, b_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += b_y.size(0)\n",
    "            correct += (predicted == b_y).squeeze().sum().numpy()\n",
    "            loss_sigma += loss.item()\n",
    "\n",
    "            if step % 10 == 5:\n",
    "                loss_avg = loss_sigma / 10\n",
    "                loss_sigma = 0.0\n",
    "                print(\"Training: Epoch[{:0>3}/{:0>3}] Iteration[{:0>3}/{:0>3}] Loss: {:.4f} Acc:{:.4%}\".format(\n",
    "                    epoch + 1, max_epoch, step + 1, len(train_loader), loss_avg, correct / total))\n",
    "\n",
    "        scheduler.step()  # 更新学习率\n",
    "        loss_sigma = 0.0\n",
    "        cls_num = 2\n",
    "        conf_mat = np.zeros([cls_num, cls_num])  # 混淆矩阵\n",
    "        \n",
    "        cnn.eval()\n",
    "        outputs = cnn(x_verify.astype(np.float32))\n",
    "        outputs.detach()\n",
    "\n",
    "        y2 = torch.from_numpy(y_verify.astype(np.int64))\n",
    "        y2 = torch.reshape(y2,(-1,1))\n",
    "        y2 = y2.squeeze_()\n",
    "        loss = loss_function(outputs,y2)\n",
    "        loss_sigma += loss.item()\n",
    "\n",
    "        cnn.train()\n",
    "        \n",
    "        test_out = outputs\n",
    "        predict_y = torch.argmax(test_out, 1).data.numpy()\n",
    "        current_acc = sum(predict_y == y_test) * 100 / len(predict_y)\n",
    "        if current_acc > max_acc:\n",
    "            max_acc = current_acc\n",
    "            max_test = predict_y\n",
    "\n",
    "        print('Epoch={} -  Test set Accuracy:{:.4%}'.format( epoch,  current_acc/100.0 ))\n",
    "\n",
    "    print('finished training')\n",
    "    print('ACC= %.4f%%' % max_acc)\n",
    "    print(max_test)\n",
    "    print(y_test)\n",
    "    print(max_test - y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
